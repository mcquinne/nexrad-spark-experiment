apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'com.bmuschko.docker-remote-api'
apply plugin: 'scala'

import com.bmuschko.gradle.docker.tasks.image.Dockerfile
import com.bmuschko.gradle.docker.tasks.image.DockerBuildImage

group = 'mcquinne.nexrad'
version = '0.1'

dependencies {
  compileOnly 'org.apache.spark:spark-core_2.11:2.0.2'

  compile 'com.amazonaws:aws-java-sdk-s3:1.11.68'
}

jar {
  manifest {
    attributes 'Main-Class': 'mcquinne.nexrad.TotalSizeS3Files'
  }
}

def dockerDir = new File(buildDir, 'docker')

task copyOutputsToDockerDir(type: Copy) {
  dependsOn shadowJar

  from { shadowJar.outputs.files.singleFile }
  into dockerDir
}

task createDockerfile(type: Dockerfile) {
  dependsOn copyOutputsToDockerDir
  destFile = new File(dockerDir, 'Dockerfile')

  from 'gettyimages/spark:2.0.2-hadoop-2.7'
  maintainer 'Evan McQuinn "mcquinne@gmail.com"'
  copyFile shadowJar.outputs.files.singleFile.name, '/opt/'
  entryPoint 'spark-submit'
  defaultCommand '--master', 'spark://master:7077', '/opt/nexrad-processor-0.1-all.jar'
}

task buildImage(type: DockerBuildImage) {
  dependsOn createDockerfile
  inputDir = dockerDir
  tag = project.name
}

build.dependsOn buildImage

task cleanService(type: Exec) {
  commandLine 'docker', 'service', 'rm', project.name
  ignoreExitValue true
}

task createService(type: Exec) {
  mustRunAfter cleanService
  dependsOn buildImage
  commandLine 'docker', 'service', 'create',
          '--name', project.name,
          '--network', 'nexrad_default', // TODO - dynamic?
          '--constraint', 'node.role == manager',
          '--restart-condition', 'none',
          project.name
}

task run {
  dependsOn cleanService, createService
}

clean.dependsOn cleanService
